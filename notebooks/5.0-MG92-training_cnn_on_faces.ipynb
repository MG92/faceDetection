{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Training a convolutional net to recognise faces</H2>\n",
    "\n",
    "The first machine learning method we will try in this experiment is the convolutional neural net (CNN), which is very popular for image processing, as convolutional layers mean it is able to work with large numbers of dimensions, such as in images.\n",
    "\n",
    "In a previous notebook, we created a dictionary of (82% accurate) labelled faces which was stored in a .txt file, so we'll load this rather than re-calculating. See notebook 4.1-MG92-extract-faces-with-names.ipynb to see the method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import spacy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from scipy.io import loadmat\n",
    "from skimage.transform import rescale\n",
    "from tensorflow.contrib import lookup\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "load_extr = np.load('../data/processed/labelled_faces.txt')\n",
    "correct_extracts = dict(load_extr[()])\n",
    "print(len(correct_extracts['Norah Jones']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original labels: 1234 \n",
      "Length of labels after cleaning: 1223\n",
      "Shape of one-hot encoded labels:  (1234, 1223)\n"
     ]
    }
   ],
   "source": [
    "#Clean the data\n",
    "#stopwords = ['actor', 'jan', 'out', 'abc', 'ap photo', 'ap ph', 'capital hill']\n",
    "#act_labels = [word.lower() for word in list(correct_extracts.keys())]\n",
    "\n",
    "act_labels = str(act_labels).replace('>','').replace('<','').replace('\\\\','')\\\n",
    "            .replace('`','').replace('\\'','').replace('[','').replace(']','')\\\n",
    "            .replace('  ',' ').strip().split(', ')\n",
    "\n",
    "unq_labels = np.unique(act_labels)\n",
    "        \n",
    "clean_labels = [word for word in unq_labels if word.lower()] #not in stopwords and not \n",
    "                #word.isdigit()]  \n",
    "\n",
    "print('Length of original labels: %d \\nLength of labels after cleaning: %d'%(len(act_labels),\n",
    "                                                                            len(clean_labels)))\n",
    "\n",
    "indcs = [clean_labels.index(word.lower()) for word in act_labels]\n",
    "one_hot_labels = tf.one_hot(indices= indcs , depth=len(clean_labels))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    o_h_labels =  (sess.run(one_hot_labels))\n",
    "    \n",
    "print('Shape of one-hot encoded labels: ', o_h_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training the CNN</h2>\n",
    "First, we must address the fact that all of the face extract images will be different shapes. To do this, we will reshape each image to the smallest shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Norah Jones image 1: (104, 104, 3)\n",
      "Shape of Norah Jones image 2: (97, 97, 3)\n",
      "Shape of Norah Jones image 3: (114, 114, 3)\n",
      "Minumum shape of Norah Jones images: 97\n"
     ]
    }
   ],
   "source": [
    "celeb_name = 'Norah Jones'\n",
    "\n",
    "print('Shape of %s image 1: %s'%(celeb_name,np.shape(correct_extracts[celeb_name][0])))\n",
    "print('Shape of %s image 2: %s'%(celeb_name,np.shape(correct_extracts[celeb_name][1])))\n",
    "print('Shape of %s image 3: %s'%(celeb_name,np.shape(correct_extracts[celeb_name][2])))\n",
    "\n",
    "print('Minumum shape of %s images: %s'%(celeb_name,min([len(extr) for extr in correct_extracts[celeb_name]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"reshaped_extracts = {}\\nfor name, imgs in correct_extracts.items():\\n    print(name)\\n    min_shape = min([len(extr) for extr in correct_extracts[name]])\\n    new_imgs = []\\n    for img in imgs:\\n        new_img = rescale(img, (len(img)/min_shape))\\n        new_imgs.append(new_img)\\n    print('Shape of new images %s'%np.shape(new_imgs))\\n    reshaped_extracts[name]=new_imgs\\n    if name=='Bush':\\n        break\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''reshaped_extracts = {}\n",
    "for name, imgs in correct_extracts.items():\n",
    "    print(name)\n",
    "    min_shape = min([len(extr) for extr in correct_extracts[name]])\n",
    "    new_imgs = []\n",
    "    for img in imgs:\n",
    "        new_img = rescale(img, (len(img)/min_shape))\n",
    "        new_imgs.append(new_img)\n",
    "    print('Shape of new images %s'%np.shape(new_imgs))\n",
    "    reshaped_extracts[name]=new_imgs\n",
    "    if name=='Bush':\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_place = tf.placeholder(tf.float32, [None,512,512,1])\n",
    "batch_size=1\n",
    "mtm =0.9\n",
    "g_dim = 16\n",
    "z_dim=100\n",
    "epsilon = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_img):\n",
    "    input_layer = tf.reshape(input_img, [-1,64,64,1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer,\n",
    "                             filters=32,\n",
    "                             kernel_size=[5, 5],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.relu\n",
    "                            )\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1,\n",
    "                             filters=64,\n",
    "                             kernel_size=[5, 5],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.relu\n",
    "                            )\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(input_, scop,train=True):\n",
    "    return tf.contrib.layers.batch_norm(input_, decay=mtm, updates_collections=None,\n",
    "    epsilon=epsilon,scale=True,is_training=train,scope=\"batch_norm_{}\".format(scop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(input_, output_dim, scop):\n",
    "    with tf.variable_scope('lin_{}'.format(scop)) as scope:\n",
    "        shape = input_.get_shape().as_list()\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_dim], tf.float32,\n",
    "            tf.random_normal_initializer())\n",
    "        bias = tf.get_variable(\"bias\",[output_dim],initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(input_, matrix)+bias, matrix, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, scop, k_h=5, k_w=5):\n",
    "    with tf.variable_scope('conv{}'.format(scop)) as scope:\n",
    "        w=tf.get_variable('w{}'.format(scop), [k_h, k_w,input_.get_shape()[-1],output_dim],\n",
    "            initializer=tf.truncated_normal_initializer(), dtype=tf.float32)\n",
    "        conv=tf.nn.conv2d(input_, w, strides=[1,2,2,1], padding='SAME')\n",
    "        b=tf.get_variable('b',[output_dim],initializer=tf.constant_initializer(0.0))\n",
    "        conv=tf.reshape(tf.nn.bias_add(conv,b),conv.get_shape())\n",
    "    return conv, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(input_, output_size, scop, k_h=5, k_w=5):\n",
    "    with tf.variable_scope('deconv{}'.format(scop)) as scope:\n",
    "        w=tf.get_variable('w{}'.format(scop), [k_h, k_w, output_size[-1], input_.get_shape()[-1] ],\n",
    "            initializer=tf.random_normal_initializer(), dtype=tf.float32)\n",
    "        conv=tf.nn.conv2d_transpose(input_, w, output_shape=output_size, strides=[1,2,2,1], padding='SAME')\n",
    "        b=tf.get_variable('b',[output_size[-1]],initializer=tf.constant_initializer(0.0))\n",
    "        deconv=tf.reshape(tf.nn.bias_add(conv,b),conv.get_shape())\n",
    "    return deconv, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64 3\n",
      "shape h4 Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "(1, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "def generator(z, img_w, img_h, img_d):\n",
    "    #z0,w0,b0=linear(z, img_h*img_w*img_d*g_dim*8/(16*16*16), 'gen') #None * 144*9*9*1*8 = 5832\n",
    "    h0=tf.reshape(z, [-1, int(img_w/16), int(img_h/16), g_dim*8]) #9*9*1*8*14 = 5832\n",
    "    h0 = tf.nn.relu(batch_norm(h0, \"h0\"))\n",
    "\n",
    "    c1, w1, b1 = deconv2d(h0, [batch_size, int(img_w/8), int(img_h/8), g_dim*4],'_1' ) #10*18*18*18*576 = 33592320\n",
    "    h1= tf.nn.relu(batch_norm(c1,\"h1\"))\n",
    "\n",
    "    c2, w2, b2 = deconv2d(h1, [batch_size, int(img_w/4), int(img_h/4), g_dim*2],'_2' )\n",
    "    h2 =tf.nn.relu(batch_norm(c2,\"h2\"))\n",
    "\n",
    "    c3, w3, b3 = deconv2d(h2, [batch_size, int(img_w/2), int(img_h/2), g_dim],'_3' )\n",
    "    h3 =tf.nn.relu(batch_norm(c3,\"h3\"))\n",
    "\n",
    "    c4, w4, b4 = deconv2d(h3, [batch_size, img_w, img_h, 1],'_4' )\n",
    "    h4=tf.nn.tanh(c4)\n",
    "\n",
    "    print(\"shape h4\",tf.shape(h4))\n",
    "    theta_g = [w1, w2, w3, w4, b1, b2, b3, b4]\n",
    "    return h4, theta_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(x,img_w, img_h, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    x=tf.reshape(x, shape=[batch_size,img_w, img_h,1])\n",
    "    x=tf.cast(x, tf.float32)\n",
    "\n",
    "    c1, w1, b1=conv2d(x ,16, '_1')\n",
    "    h1=tf.nn.relu(batch_norm(c1,\"d_h1\"))\n",
    "\n",
    "    c2, w2, b2=conv2d(h1,32, '_2')\n",
    "    h2=tf.nn.relu(batch_norm(c2,\"d_h2\"))\n",
    "\n",
    "    c3, w3, b3=conv2d(h2,64, '_3')\n",
    "    h3=tf.nn.relu(batch_norm(c3,\"d_h3\"))\n",
    "    h3=tf.reshape(h3, [batch_size,-1])\n",
    "\n",
    "    l4, w4, b4=linear(h3,1223, 'dis')\n",
    "    h4=tf.nn.sigmoid(l4)\n",
    "    \n",
    "    #theta_d=[w1, w2, w3, w4, b1, b2, b3, b4]\n",
    "    return h4,l4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64 3\n",
      "shape h4 Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "(1, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "example_img = rescale(correct_extracts[celeb_name][1], (64/len(correct_extracts[celeb_name][1])))\n",
    "img_w, img_h, img_d = np.shape(example_img)[0], np.shape(example_img)[1], np.shape(example_img)[2]\n",
    "print(img_w, img_h, img_d)\n",
    "z = tf.placeholder(tf.float32, shape=[None,z_dim])\n",
    "g_z, theta_g = generator(z, img_w, img_h, img_d)\n",
    "print(np.shape(g_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid:0\", shape=(1, 1223), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None]+[img_h,img_w])\n",
    "d_x, logits_x = build_cnn(x,img_w, img_h)\n",
    "print(d_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1, 1223) and (1223,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-b425088e8384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mo_h_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_op = optimizer.minimize(loss=loss,\n\u001b[1;32m      4\u001b[0m                               global_step=tf.train.get_global_step())\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy\u001b[0;34m(onehot_labels, logits, weights, label_smoothing, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0monehot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \"\"\"\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1, 1223) and (1223,) are incompatible"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=o_h_labels[1], logits=logits_x)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss=loss,\n",
    "                              global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
